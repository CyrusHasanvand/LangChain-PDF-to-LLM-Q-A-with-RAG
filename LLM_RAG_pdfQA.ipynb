{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374b6d89-1b9d-4e33-a420-169a6da318c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fd7fef-901d-4cf9-87ec-34a6434a2b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle  # For saving FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c3dde97-621c-450b-9cb4-17fdd8209289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757ea6b-66ba-4a30-8bc1-1f4129eb3834",
   "metadata": {},
   "source": [
    "## Load and Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f271ce-f816-4dfb-b4aa-d4acd226e5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data_Path = r\"D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\"\n",
    "FAISS_Path = r\"D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\\FAISS_DB\\UFAREX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e3075e-47b1-428b-b0f1-e9f22cb6dc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(Data_Path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969bf6d6-676b-44b5-8f92-dd529db4ca24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 93\n"
     ]
    }
   ],
   "source": [
    "print(type(chunks), len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58a1704-0d7b-436f-8e02-fdc2d9bb6aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, VOL. 54, NO. 12, DECEMBER 2024 7419\n",
      "UFAREX: A Universal Fully Autonomous Robust\n",
      "Expansionist Fuzzy System for Optimal Online\n",
      "Learning From Nonstationary Data Streams\n",
      "Cyrus Hasanvand , Hamid Hasanvand , and Hamidreza Momeni , Senior Member, IEEE\n",
      "Abstract—Online intelligent knowledge extraction from real-\n",
      "world nonstationary data streams presents a multiobjective\n",
      "optimization challenge. Here, we characterize the learning pro-\n",
      "cess on a trajectory of global optimality to simultaneously satisfy\n",
      "six high-proﬁle objectives: 1) optimum generalization for the\n",
      "best bias-variance tradeoff; 2) compactness of knowledgebase;\n",
      "3) memory retention and stability-plasticity balance; 4) univer-\n",
      "sality and full autonomy; 5) robustness against outliers, noise,\n",
      "and model uncertainty; and 6) active concept drift detection\n",
      "and adaptation. We propose a ﬂexible Takagi–Sugeno (TS) fuzzy\n",
      "system, named UFAREX, that self-constructs and self-guards' metadata={'producer': 'Acrobat Distiller 24.0 (Windows); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV', 'creator': 'LaTeX with hyperref package', 'creationdate': '2024-11-08T11:59:08+05:30', 'moddate': '2024-12-15T16:54:15+03:30', 'ieee publication id': '6221021', 'ieee issue id': '10758325', 'title': 'UFAREX: A Universal Fully Autonomous Robust Expansionist Fuzzy System for Optimal Online Learning From Nonstationary Data Streams', 'ieee article id': '10695143', 'subject': 'IEEE Transactions on Systems, Man, and Cybernetics: Systems;2024;54;12;10.1109/TSMC.2024.3454541', 'source': 'D:\\\\WorkPlace\\\\Python\\\\Training\\\\May2025\\\\Practice\\\\PracLLM\\\\Cyrus Hasanvand - 2024_ UFAREX_ IEEE Trans on SMCA.pdf', 'total_pages': 15, 'page': 0, 'page_label': '7419'}\n"
     ]
    }
   ],
   "source": [
    "print((chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa9ffc2-a2ba-48be-a81d-024ee62901f1",
   "metadata": {},
   "source": [
    "## Embed and Build FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e6ce48e-a3dd-408b-84d9-238af835180a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#embedding_model = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(chunks, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb724b-454d-4954-8200-7a930736090c",
   "metadata": {},
   "source": [
    "## Save the FAISS DB (Persistence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03b4f1-d785-40f1-8980-cec972a39065",
   "metadata": {},
   "source": [
    "Unlike Chroma (which has persist_directory), FAISS requires manual saving using faiss + pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cedad23-57ea-4bae-8585-34cbd81da9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 93 chunks to D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\\FAISS_DB\\UFAREX\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FAISS_Path):\n",
    "    shutil.rmtree(FAISS_Path) # Delete the folder and its contents\n",
    "os.makedirs(FAISS_Path, exist_ok=True) # Re-create the folder\n",
    "\n",
    "# Save index\n",
    "index_path = os.path.join(FAISS_Path, \"index.faiss\")\n",
    "faiss.write_index(vectorstore.index, index_path)\n",
    "\n",
    "# Save documents and embeddings separately\n",
    "store_path = os.path.join(FAISS_Path, \"store.pkl\")\n",
    "with open(store_path, \"wb\") as f:\n",
    "    pickle.dump(vectorstore, f)\n",
    "\n",
    "print(f\"Saved {len(chunks)} chunks to {FAISS_Path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f9aca-2905-4484-9419-0eafe55eb234",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the FAISS DB Later\n",
    "\n",
    "When you want to reload your saved FAISS database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8da5b0-5aa2-4066-b851-5b5397812fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "FAISS_Path = r\"D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\\FAISS_DB\\UFAREX\"\n",
    "\n",
    "index_path = os.path.join(FAISS_Path, \"index.faiss\")\n",
    "store_path = os.path.join(FAISS_Path, \"store.pkl\")\n",
    "\n",
    "with open(store_path, \"rb\") as f:\n",
    "    vectorstore = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e02b9e-2078-42d4-94b5-75be8a39f5aa",
   "metadata": {},
   "source": [
    "## Add New Documents to Existing FAISS VectorStore\n",
    "### Load or prepare new documents\n",
    "I already have __**vectorstore**__ from previous cell.\n",
    "\n",
    "Use any method to get new chunks. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b9cd4-547e-40bd-bfbe-fff0eae31049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "New_Data_Path = r\"D:\\NewDocuments\"\n",
    "\n",
    "loader = PyPDFDirectoryLoader(New_Data_Path)\n",
    "new_docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "new_chunks = text_splitter.split_documents(new_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d1d94-97dc-42e4-806f-5209316568cc",
   "metadata": {},
   "source": [
    "### Add new chunks to the existing vectorstore\n",
    "This step embeds the new chunks using the original embedding model (automatically stored in the vectorstore) and adds them to the FAISS index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5383956-da7f-4cd4-8a74-56c5b5ee7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(new_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759cf79-2f57-4250-bf8e-14c0cd651b04",
   "metadata": {},
   "source": [
    "### Save the updated vectorstore again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8ca65-f87a-4edc-a9cb-829b23853009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Save updated FAISS index\n",
    "index_path = os.path.join(FAISS_Path, \"index.faiss\")\n",
    "faiss.write_index(vectorstore.index, index_path)\n",
    "\n",
    "# Save updated full store\n",
    "store_path = os.path.join(FAISS_Path, \"store.pkl\")\n",
    "with open(store_path, \"wb\") as f:\n",
    "    pickle.dump(vectorstore, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da1953-d2e5-4e5d-8a75-25e854623fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ef63f7-ded0-4b12-a780-08c152742ef6",
   "metadata": {},
   "source": [
    "## Load for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a7306-3fe1-4044-9545-dda14f17e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search(\"your query\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89221535-cd77-4a54-a40e-5a59bfd77c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbert_env)",
   "language": "python",
   "name": "sbert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
