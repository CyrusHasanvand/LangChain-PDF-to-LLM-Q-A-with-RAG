{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374b6d89-1b9d-4e33-a420-169a6da318c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fd7fef-901d-4cf9-87ec-34a6434a2b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle  # For saving FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3dde97-621c-450b-9cb4-17fdd8209289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757ea6b-66ba-4a30-8bc1-1f4129eb3834",
   "metadata": {},
   "source": [
    "## Load and Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f271ce-f816-4dfb-b4aa-d4acd226e5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data_Path = r\"D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\"\n",
    "FAISS_Path = r\"D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\\FAISS_DB\\UFAREX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e3075e-47b1-428b-b0f1-e9f22cb6dc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(Data_Path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "969bf6d6-676b-44b5-8f92-dd529db4ca24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 93\n"
     ]
    }
   ],
   "source": [
    "print(type(chunks), len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58a1704-0d7b-436f-8e02-fdc2d9bb6aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS: SYSTEMS, VOL. 54, NO. 12, DECEMBER 2024 7419\n",
      "UFAREX: A Universal Fully Autonomous Robust\n",
      "Expansionist Fuzzy System for Optimal Online\n",
      "Learning From Nonstationary Data Streams\n",
      "Cyrus Hasanvand , Hamid Hasanvand , and Hamidreza Momeni , Senior Member, IEEE\n",
      "Abstract—Online intelligent knowledge extraction from real-\n",
      "world nonstationary data streams presents a multiobjective\n",
      "optimization challenge. Here, we characterize the learning pro-\n",
      "cess on a trajectory of global optimality to simultaneously satisfy\n",
      "six high-proﬁle objectives: 1) optimum generalization for the\n",
      "best bias-variance tradeoff; 2) compactness of knowledgebase;\n",
      "3) memory retention and stability-plasticity balance; 4) univer-\n",
      "sality and full autonomy; 5) robustness against outliers, noise,\n",
      "and model uncertainty; and 6) active concept drift detection\n",
      "and adaptation. We propose a ﬂexible Takagi–Sugeno (TS) fuzzy\n",
      "system, named UFAREX, that self-constructs and self-guards' metadata={'producer': 'Acrobat Distiller 24.0 (Windows); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV', 'creator': 'LaTeX with hyperref package', 'creationdate': '2024-11-08T11:59:08+05:30', 'moddate': '2024-12-15T16:54:15+03:30', 'ieee publication id': '6221021', 'ieee issue id': '10758325', 'title': 'UFAREX: A Universal Fully Autonomous Robust Expansionist Fuzzy System for Optimal Online Learning From Nonstationary Data Streams', 'ieee article id': '10695143', 'subject': 'IEEE Transactions on Systems, Man, and Cybernetics: Systems;2024;54;12;10.1109/TSMC.2024.3454541', 'source': 'D:\\\\WorkPlace\\\\Python\\\\Training\\\\May2025\\\\Practice\\\\PracLLM\\\\Cyrus Hasanvand - 2024_ UFAREX_ IEEE Trans on SMCA.pdf', 'total_pages': 15, 'page': 0, 'page_label': '7419'}\n"
     ]
    }
   ],
   "source": [
    "print((chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa9ffc2-a2ba-48be-a81d-024ee62901f1",
   "metadata": {},
   "source": [
    "## Embed and Build FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e6ce48e-a3dd-408b-84d9-238af835180a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#embedding_model = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(chunks, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb724b-454d-4954-8200-7a930736090c",
   "metadata": {},
   "source": [
    "## Save the FAISS DB (Persistence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03b4f1-d785-40f1-8980-cec972a39065",
   "metadata": {},
   "source": [
    "Unlike Chroma (which has persist_directory), FAISS requires manual saving using faiss + pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cedad23-57ea-4bae-8585-34cbd81da9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 93 chunks to D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\\FAISS_DB\\UFAREX\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FAISS_Path):\n",
    "    shutil.rmtree(FAISS_Path) # Delete the folder and its contents\n",
    "os.makedirs(FAISS_Path, exist_ok=True) # Re-create the folder\n",
    "\n",
    "# Save index\n",
    "index_path = os.path.join(FAISS_Path, \"index.faiss\")\n",
    "faiss.write_index(vectorstore.index, index_path)\n",
    "\n",
    "# Save documents and embeddings separately\n",
    "store_path = os.path.join(FAISS_Path, \"store.pkl\")\n",
    "with open(store_path, \"wb\") as f:\n",
    "    pickle.dump(vectorstore, f)\n",
    "\n",
    "print(f\"Saved {len(chunks)} chunks to {FAISS_Path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f9aca-2905-4484-9419-0eafe55eb234",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the FAISS DB Later\n",
    "\n",
    "When you want to reload your saved FAISS database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8da5b0-5aa2-4066-b851-5b5397812fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cyrus\\anaconda3\\envs\\sbert_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "FAISS_Path = r\"D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\\FAISS_DB\\UFAREX\"\n",
    "\n",
    "index_path = os.path.join(FAISS_Path, \"index.faiss\")\n",
    "store_path = os.path.join(FAISS_Path, \"store.pkl\")\n",
    "\n",
    "with open(store_path, \"rb\") as f:\n",
    "    vectorstore = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e02b9e-2078-42d4-94b5-75be8a39f5aa",
   "metadata": {},
   "source": [
    "## Add New Documents to Existing FAISS VectorStore\n",
    "### Load or prepare new documents\n",
    "I already have __**vectorstore**__ from previous cell.\n",
    "\n",
    "Use any method to get new chunks. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b9cd4-547e-40bd-bfbe-fff0eae31049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "New_Data_Path = r\"D:\\NewDocuments\"\n",
    "\n",
    "loader = PyPDFDirectoryLoader(New_Data_Path)\n",
    "new_docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "new_chunks = text_splitter.split_documents(new_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d1d94-97dc-42e4-806f-5209316568cc",
   "metadata": {},
   "source": [
    "### Add new chunks to the existing vectorstore\n",
    "This step embeds the new chunks using the original embedding model (automatically stored in the vectorstore) and adds them to the FAISS index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5383956-da7f-4cd4-8a74-56c5b5ee7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.add_documents(new_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759cf79-2f57-4250-bf8e-14c0cd651b04",
   "metadata": {},
   "source": [
    "### Save the updated vectorstore again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8ca65-f87a-4edc-a9cb-829b23853009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Save updated FAISS index\n",
    "index_path = os.path.join(FAISS_Path, \"index.faiss\")\n",
    "faiss.write_index(vectorstore.index, index_path)\n",
    "\n",
    "# Save updated full store\n",
    "store_path = os.path.join(FAISS_Path, \"store.pkl\")\n",
    "with open(store_path, \"wb\") as f:\n",
    "    pickle.dump(vectorstore, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da1953-d2e5-4e5d-8a75-25e854623fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ef63f7-ded0-4b12-a780-08c152742ef6",
   "metadata": {},
   "source": [
    "## Load for search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc3a7306-3fe1-4044-9545-dda14f17e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query=\"definition of nonstationary data streams (NDS)\"\n",
    "Results = vectorstore.similarity_search(Query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89221535-cd77-4a54-a40e-5a59bfd77c95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "D:\\WorkPlace\\Python\\Training\\May2025\\Practice\\PracLLM\\Cyrus Hasanvand - 2024_ UFAREX_ IEEE Trans on SMCA.pdf\n",
      "page_content='agement with zero buffer latency for regression applications. No\n",
      "heuristic forgetting, pruning, splitting, merging, and weighting\n",
      "mechanisms are exercised to prevent human intervention and\n",
      "render universality. UFAREX was comparatively tested on four\n",
      "real-world benchmarks. It stands out as an autonomous system\n",
      "geared for adaptive modeling, time-series forecasting, anomaly\n",
      "monitoring, and robust fault detection and diagnosis.\n",
      "Index Terms—Active concept drift detection and adaptation,\n",
      "adaptive prediction intervals (APIs), catastrophic forgetting (CF),\n",
      "noise and outlier, nonstationary data streams (NDSs), uncertainty.\n",
      "I. I NTRODUCTION\n",
      "O\n",
      "NLINE knowledge discovery from real-world non-\n",
      "stationary data streams (NDSs) presents profound\n",
      "challenges to the design of modern computational intelligence.\n",
      "Manuscript received 4 June 2024; accepted 20 August 2024. Date of pub-\n",
      "lication 26 September 2024; date of current version 20 November 2024. This' metadata={'producer': 'Acrobat Distiller 24.0 (Windows); modified using iText® Core 7.2.4 (AGPL version) ©2000-2022 iText Group NV', 'creator': 'LaTeX with hyperref package', 'creationdate': '2024-11-08T11:59:08+05:30', 'moddate': '2024-12-15T16:54:15+03:30', 'ieee publication id': '6221021', 'ieee issue id': '10758325', 'title': 'UFAREX: A Universal Fully Autonomous Robust Expansionist Fuzzy System for Optimal Online Learning From Nonstationary Data Streams', 'ieee article id': '10695143', 'subject': 'IEEE Transactions on Systems, Man, and Cybernetics: Systems;2024;54;12;10.1109/TSMC.2024.3454541', 'source': 'D:\\\\WorkPlace\\\\Python\\\\Training\\\\May2025\\\\Practice\\\\PracLLM\\\\Cyrus Hasanvand - 2024_ UFAREX_ IEEE Trans on SMCA.pdf', 'total_pages': 15, 'page': 0, 'page_label': '7419'}\n"
     ]
    }
   ],
   "source": [
    "print(type(Results))\n",
    "print(type(Results[0].page_content))\n",
    "#print((results[0].page_content))\n",
    "print((Results[0].metadata['source']))\n",
    "\n",
    "print((Results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a96b40-03f6-4e80-b86d-c28f209a8d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d382b7c-0f09-4b74-ac1a-40ba3093d8b5",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c3d668cd-7049-4ee3-918d-f0ea5e5a4ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "#from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage, StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "#from langchain_huggingface import HuggingFacePipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41fbb752-4b2f-4b19-8238-625f53add228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLM = ChatOllama(model=\"llama3.1\", Temperature=0.7,do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b86a87f6-bd5f-44f1-b8d4-d9ce8f60619c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    ('system','You are an AI assistant, which refines the orders of similarity search from FAISS database and provides no more than 220 tokens when writing a response to a question'),\n",
    "    ('user','{text}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d98878b9-2ef0-4495-826f-6cf96b519061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ChainLLama31=prompt|LLM|StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "684763de-52ed-4778-9f61-13fed250fa86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Question = f'''\n",
    "You are given the results of a FAISS similarity search. \n",
    "The user asked the following query:\n",
    "Query: \"{Query}\"\n",
    "\n",
    "Here are the retrieved results:\n",
    "Result[0]: {Results[0].page_content}\n",
    "Result[1]: {Results[1].page_content}\n",
    "Result[2]: {Results[2].page_content}\n",
    "Result[3]: {Results[3].page_content}\n",
    "Result[4]: {Results[4].page_content}\n",
    "\n",
    "Please re-order these results in order of **relevance to the user's query**,\n",
    "starting with the most relevant. \n",
    "In your answer, you can refer to them by their original indices, e.g., Result[0],\n",
    "Result[1], etc., and optionally explain why each result is in that position.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5a0fd524-78a0-4c12-916c-0d4e5136474d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Response_message=ChainLLama31.invoke({'text':Question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2ce2bcd8-c735-45ae-ab6a-b7c14bdb168b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After analyzing the results, I've reordered them based on relevance to the user's query \"definition of nonstationary data streams (NDS)\". Here are the results:\n",
      "\n",
      "1. **Result[1]**: The core theme of NDS is concept drift. It results in conflict between the old and new trends... This result directly answers the user's question by defining a key aspect of NDS.\n",
      "2. **Result[0]**: Online knowledge discovery from real-world non-stationary data streams (NDSs) presents profound challenges to the design of modern computational intelligence... While this result doesn't explicitly define NDS, it mentions it and discusses its challenges, making it highly relevant.\n",
      "3. **Result[4]**: ...the sole dominant rule undertakes the prediction task... This result is less directly related to defining NDS, but it does discuss a concept drift within the context of NDS, which makes it somewhat relevant.\n",
      "4. **Result[2]**: Thus, the sole dominant rule undertakes the prediction task... This result is similar to Result[4] and discusses the detection of recurrent drifts in NDS, but with less focus on defining the term itself.\n",
      "5. **Result[3]**: C. Philosophy and Design... In quest of optimality and rule-base compactness, we hold interest in finding minimal ℜ local linear regions in NDS that can be sequentially extracted by TS rules... This result is the least directly related to defining NDS and appears to discuss a specific design aspect rather than providing a definition.\n",
      "\n",
      "The ordering is based on how directly each result addresses the user's query. Result[1] provides a clear definition of concept drift within the context of NDS, making it the most relevant.\n"
     ]
    }
   ],
   "source": [
    "print(Response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5c517-db92-4421-830b-a332bf9e64a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a326afc-fabe-470e-88ea-30c658a0f911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007321bc-ca8d-4872-a402-38d5e170d472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058047b9-c5d8-46d8-8b0f-1684f241cdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbert_env)",
   "language": "python",
   "name": "sbert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
